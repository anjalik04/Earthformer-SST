layout:
  in_len: 12
  out_len: 12
  img_height: 720
  img_width: 1440
optim:
  seed: 2022
  total_batch_size: 32
  micro_batch_size: 2
  method: adamw
  lr: 0.0001
  wd: 0.05
  gradient_clip_val: 1.0
  max_epochs: 100
  warmup_percentage: 0.2
  lr_scheduler_mode: cosine
  min_lr_ratio: 0.001
  warmup_min_lr_ratio: 0.0
  save_top_k: 1
  early_stop: true
  early_stop_mode: min
  early_stop_patience: 5
logging:
  logging_prefix: SST_Forecasting
  monitor_lr: true
  monitor_device: false
  save_dir: lightning_logs/sst
  project: earthformer
  name: cuboid_transformer_sst_singlefile
trainer:
  check_val_every_n_epoch: 1
  log_step_ratio: 0.01
  precision: 16
  gpus: 1
  strategy: ddp
  max_epochs: 50
model:
  data_channels: 1
  input_shape:
  - 52
  - 21
  - 28
  - 1
  target_shape:
  - 52
  - 21
  - 28
  - 1
  base_units: 64
  block_units: null
  scale_alpha: 1.0
  enc_depth:
  - 1
  - 1
  dec_depth:
  - 1
  - 1
  enc_use_inter_ffn: true
  dec_use_inter_ffn: true
  dec_hierarchical_pos_embed: true
  downsample: 2
  downsample_type: patch_merge
  upsample_type: upsample
  self_pattern: axial
  cross_self_pattern: axial
  cross_pattern: cross_1x1
  attn_drop: 0.1
  proj_drop: 0.1
  ffn_drop: 0.1
  num_heads: 8
  ffn_activation: gelu
  gated_ffn: false
  norm_layer: layer_norm
  padding_type: zeros
  checkpoint_level: 2
  _target_: src.earthformer.cuboid_transformer.CuboidTransformerModel
  in_len: 52
  out_len: 52
  in_channels: 1
  out_channels: 1
  num_blocks: 1
  num_layers: 6
  num_global_vectors: 8
  dim: 512
  hidden_dim: 2048
  encoder_depth: 3
  decoder_depth: 3
  use_global_vector: true
  use_autoregression: false
  loss: mae
  metrics:
  - mse
  - mae
  - rmse
dataset:
  in_len: 52
  out_len: 52
  batch_size: 2
  num_workers: 2
  train_start_year: 1981
  val_start_year: 2016
  test_start_year: 2021
  end_year: 2025
  _target_: src.earthformer.datasets.sst.sst_datamodule.SSTDataModule
  data_root: /content/data
  train_end_year: 2015
  val_end_year: 2020
seed: 2022
data_root: /content/data
in_len: 52
out_len: 52
batch_size: 2
num_workers: 2
train_end_year: 2015
val_end_year: 2020
